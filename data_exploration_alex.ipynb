{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54b43ac",
   "metadata": {},
   "source": [
    "By Alexander Stratton / als15@illinois.edu / Copyright 2022. All Rights Reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2b4961",
   "metadata": {},
   "source": [
    "References:\n",
    "    - https://github.com/echen102/ukraine-russia/tree/master/2022-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f1fd3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from csv import writer\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tqdm\n",
    "from twarc import Twarc\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tk = TweetTokenizer()\n",
    "tw = Twarc('consumer_key', 'consumer_key_secret', 'access_token', 'access_token_secret')\n",
    "path = str(Path.cwd()) + '/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b42d7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function hydrates the tweets and writes them to a csv file.\n",
    "# Twarc comes with a prepackaged hydrate script, but I wanted to save only part of the information it retrieves \\\n",
    "# and I wanted it as a csv not a json.\n",
    "\n",
    "def hydrate(path, file):\n",
    "    csvFile = open(file, \"a\", newline=\"\", encoding='utf-8')\n",
    "    csvWriter = writer(csvFile)\n",
    "    \n",
    "    \n",
    "    for tweet in tw.hydrate(open(path)):\n",
    "        tweet_id = tweet['id']\n",
    "        text = tweet['full_text']\n",
    "        \n",
    "        tweet = [tweet_id, text]\n",
    "        csvWriter.writerow(tweet)\n",
    "        \n",
    "    csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bbcabe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(os.path.join(path, \"*.txt\"))\n",
    "li = [pd.read_csv(filename, sep=\" \", header=None) for filename in all_files]\n",
    "all_tweets = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ac9966df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3029712"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how many tweets the dataset has for one day (2022-04-01).\n",
    "\n",
    "len(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2146584",
   "metadata": {},
   "outputs": [],
   "source": [
    "need_verbs = ['needs', 'need', 'needing', 'require', 'requiring', 'needed',\n",
    "              'required', 'demand', 'demands', 'demanding', 'request', 'requesting', 'requests']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872c25b",
   "metadata": {},
   "source": [
    "We have a limited number of tweets we can pull per month using the academic API. Thus, I am taking a subset of this one day to determine how many usable tweets are contained in this dataset. I am going to pull 10,000 tweets and look at how many contain the \"need verbs\" listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "922f869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sample = all_tweets.sample(10000)\n",
    "# Writing my sample into a txt file so I can rehydrate the tweets from their ids.\n",
    "\n",
    "with open(os.path.join(path, \"sample/sample.txt\"), 'a') as f:\n",
    "    tweets_as_string = tweet_sample.to_string(header=False, index=False)\n",
    "    f.write(tweets_as_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "105854ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = open(os.path.join(path, \"sample/sample_tweets.csv\"), \"a\", newline=\"\", encoding='utf-8')\n",
    "csvWriter = writer(csvFile)\n",
    "csvWriter.writerow(['id', 'text'])\n",
    "csvFile.close()\n",
    "\n",
    "hydrate(os.path.join(path, \"sample/sample.txt\"), os.path.join(path, \"sample/sample_tweets.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f9ae142",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(os.path.join(path, \"sample/sample_tweets.csv\"))\n",
    "tagged = [tk.tokenize(tweets.iloc[i, 1]) for i in range(len(tweets.iloc[:, 1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "739754ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_tweets = []\n",
    "\n",
    "for idx, tweet in enumerate(tagged):\n",
    "    for need in need_verbs:\n",
    "        if need in tweet:\n",
    "            usable_tweets.append(tweets.iloc[idx, 1])\n",
    "            break\n",
    "            \n",
    "ratio = len(usable_tweets) / len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d961d3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT @SteveSchmidtSES: Where are these Ukrainians? The world must demand immediate answers. This is ominous and reeks of the stench of an evi‚Ä¶',\n",
       " 'RT @KpsZSU: We have not received the tools we need to defend our sky and achieve victory.\\r\\nIn the sky, the greatest need is for fighter jet‚Ä¶',\n",
       " 'RT @watch_waste: This #FridaysForFuture, we demand you to #StopWar #UkraineWar, @WhiteHouse @EU_Commission @EUCouncil #Kremlin @JoeBiden @v‚Ä¶',\n",
       " 'RT @jcokechukwu: BREAKING: Putin signs into law, a decree requiring foreign buyers of Russian gas to pay in Rubles starting April 1. This m‚Ä¶',\n",
       " '@thehill At the ways Putin is going about the war with Ukraine,  it‚Äôs not going to halt until Ukraine totally surrender and give in to all demands from Russia.  Biden is now caught in a dilemma and NATO may be fragmented in continuing with the war.',\n",
       " 'RT @SUNNYLAND24: Sounds like there is a MAJOR need for $BYRG @buyergroupinc üëÄüëá\\n\\n#UnitedStates based and owned #Platinum #Palladium #Rhodium‚Ä¶',\n",
       " 'RT @KpsZSU: We have not received the tools we need to defend our sky and achieve victory.\\r\\nIn the sky, the greatest need is for fighter jet‚Ä¶',\n",
       " 'RT @KyivIndependent: ‚ö°Ô∏èMariupol city council: At least $10 billion needed to restore Mariupol‚Äôs infrastructure.\\n\\nAccording to mayor Vadym B‚Ä¶',\n",
       " 'RT @Non_graata: Notice Biden made an off the cuff statement about Putin needing to go and immediately US govt was forced to apologize.\\n\\nNot‚Ä¶',\n",
       " 'We need Norwegian air defense and missile defense systems now. He said this in an exclusive interview with VG.\\n\\nI would like to thank Norway for showing solidarity, as Norway has never given military aid to a non-NATO country. https://t.co/dEg4gUSnPs']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable_tweets[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "963761f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02449078564500485"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1f8e4a",
   "metadata": {},
   "source": [
    "If this sample is representative, then roughly 2.4491% of tweets are usable. If this is the case, from the dataset's almost 454.5 million tweets, aproximately 11.13 million tweets are usable. In reality, not all these tweets will be usable because while they all contain the need verbs, not all will be relevant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
